{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz0b9DRomGKh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 环境准备\n",
    "\n",
    "需要依赖：\n",
    "- datasets：加载ruby数据集\n",
    "- transformers：加载预训练模型\n",
    "- pytorch：fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GsLZGLHlS1xu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SDdPoYu31Iu5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmE7qQNfn0gL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用Colab挂载文件系统，便于训练时保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHjGdl7EnvA7",
    "outputId": "3c0d7ad9-98b5-47b8-95ec-a17b479206ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "#\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "#\n",
    "# %cd drive/MyDrive/NL-PL/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOQ8LbC2Awx-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CckfZepUmSnA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 加载预训练模型与数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "cb1f6ebaf6294b58b23f03bc9c350538",
      "be45805e1a88493fb9851f9b445a1d5e",
      "cc5d381b633445c79860e9ae46afb321",
      "e3369bc9434f4dae98e7d3b23b8a4882",
      "c65f49431b524501a2e066d4bab2ea40",
      "627bad0892b74ffba74aee2d31d15d63",
      "bd463ee0978e4fb09627d8471617c151",
      "aa387c004dba4d06bef496f5c5bc52e8",
      "cf28f5c15da54fd2887942a1b78fafd6",
      "4c3b502231b64cce9ecb61b3be78be75",
      "78e7d88ecabb4b97b5e7c4465b909462"
     ]
    },
    "id": "8naf6ZoD19DN",
    "outputId": "4c172531-d0a7-4570-e27e-dac99f7dcd00",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset code_x_glue_ct_code_to_text (/root/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/ruby/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb1f6ebaf6294b58b23f03bc9c350538"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "dataset = load_dataset('code_x_glue_ct_code_to_text', 'ruby')\n",
    "checkpoint = 'microsoft/codebert-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "config = RobertaConfig.from_pretrained(checkpoint)\n",
    "model = RobertaModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiUgT_-65B8F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 数据规范化\n",
    "\n",
    "将输入数据（code, docstring）tokenizer时进行padding，调整至同一长度\n",
    "\n",
    "code的最大长度取256，labels的最大长度取128，均参考自CodeBERT的github示例\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6JJM5YcRxPcE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_modifier(data):\n",
    "  code = data['code']\n",
    "  docstring = data['docstring']\n",
    "\n",
    "  inputs = tokenizer(code, max_length=256, padding='max_length', truncation=True)\n",
    "  labels = tokenizer(docstring, max_length=128, padding='max_length', truncation=True)\n",
    "  \n",
    "  inputs['labels'] = labels['input_ids']\n",
    "  inputs['label_mask'] = labels['attention_mask']\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ129LG1pnQp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用.map方法对每个batch的数据都做上述操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "0443e01cb173464aa098ae1a66c76697",
      "f7e5c6955eba40178e47d5d2a46d208b",
      "c4085357152e4360a10106286f011912",
      "60fbd31e9c374f738e2ac3fc136b9c2b",
      "5d351f33afe943bd8c56ed7083b4b256",
      "cc2e1192a5c34f40b299a964a32a684b",
      "b5bcaec573844a7198688521f493e561",
      "975f9de21d5a4c04b088d2988bf9ab1d",
      "9d07085ec7e3488091d890f0dbb12c5b",
      "6e9ccb8d25ee497287bc316936e90650",
      "49ac377fcf5a492c8dcd8d1fa994376e",
      "b8530610645147808dbb6e012263e262",
      "5c807713abaf4d8fb2942e83d9a7ec9f",
      "ebecfc1a99d84518b93f1504a7bfd60f",
      "de1e86f106b24098aa6c1fbb637bda71",
      "7c4f309990594b35806d0cab9f69e7fe",
      "0c1bbc07981243618741cdbc54cbebf2",
      "fcf10595b6554b199e2be35e7a443a03",
      "26c93c2044ea46ae8a706fff0c8c5b8e",
      "6b22eb842398447684ef1ec4e7a36561",
      "1d2a8d82b6924ac69ccb813ba489756d",
      "7e93b19d2c7a45a7ab6371b182eea239",
      "74a74652621e4f15b6f5adfd3ca03165",
      "7207703e15ab4e9883f16911a4050e01",
      "a5af7fba5ee4404ebb2d894de6255535",
      "ea5735e45e28417298b24c0f08b4b58b",
      "e0e47e7ac29f4f9586987a37b8c5a3da",
      "5ac2ef93aaea4b39bd0896325048872c",
      "b83e5cb2950f4371870d651814b8d2e5",
      "3b789a5ac7fd4390b7096c3970d61344",
      "14d8aed42b334b899abae5e549742911",
      "e1f6a8ae102a4a3db3291bfc0cb0ce3a",
      "4e6800e6061f4ac18c38d9a6f2c6d45a"
     ]
    },
    "id": "7zZGs3yZ3tFc",
    "outputId": "b635294c-aed1-484a-b3d1-b17870b56db7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Parameter 'function'=<function data_modifier at 0x7f513a99a290> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0443e01cb173464aa098ae1a66c76697"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8530610645147808dbb6e012263e262"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74a74652621e4f15b6f5adfd3ca03165"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "dataset = dataset.map(data_modifier, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJEdUbzG0wYq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "将数据调整到torch可用的格式，只保留需要的内容\n",
    "\n",
    "再生成模型直接可用的DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D4IJ8rKmpbRi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_format(type=\"torch\",columns=['input_ids','attention_mask','labels', 'label_mask'])\n",
    "train_loader = DataLoader(dataset['train'], shuffle=True, batch_size=16)\n",
    "valid_loader = DataLoader(dataset['validation'], batch_size=16)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjnOZpx8J8y6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型构建\n",
    "\n",
    "使用pytorch进行网络的补全和训练，网络结构为Seq2Seq结构\n",
    "\n",
    "encoder直接使用codeBERT即可，decoder使用nn.TransformerDecoderLayer实现\n",
    "\n",
    "forward部分参考自CodeBERT Github仓库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwRr7BEc1R5H",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "forward的流程：\n",
    "\n",
    "- 训练：\n",
    "  1. input和mask输入encoder，得到encoder_output\n",
    "  2. 在输入decoder之前，使用labels对encoder_output做嵌入得到词向量tgt\n",
    "  3. 将词向量和encoder的输出，作为decoder的输入，得到decoder_output\n",
    "  4. 使用tanh和线性层计算隐藏态hidden_state\n",
    "  5. 隐藏态再次通过线性层，得到输出\n",
    "\n",
    "- 预测：\n",
    "  - 需要将每一步的输出代替labels进行embedding\n",
    "  - decoder的输出需要进行一次Softmax\n",
    "  - 使用束搜索(beam search)防止误差传递，提高预测准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE-mTlOaD09d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**束搜索**：\n",
    "\n",
    "每得到一轮的输出的分数后，累加到已有的分数上，取TopK作为下一轮的输入\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AAU5yqAzj72c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 束搜索类定义\n",
    "class Beam():\n",
    "  def __init__(self, beam_size, cls, sep):\n",
    "    # topK的K值大小\n",
    "    self.size = beam_size\n",
    "    # 记录K个最高得分\n",
    "    self.scores = torch.cuda.FloatTensor(beam_size).zero_()\n",
    "    # 记录每个时间步之前的topK状态，用于回溯和计算最佳分数\n",
    "    self.prev_outputs = []\n",
    "    # 记录每个时间步的输出，初始化为0\n",
    "    self.next_outputs = [torch.cuda.LongTensor(beam_size).fill_(0)]\n",
    "    self.next_outputs[0][0] = cls\n",
    "    # 记录已完成的搜索结果\n",
    "    self.finished = []\n",
    "    self.eos = sep\n",
    "    self.eosTop = False\n",
    "\n",
    "  # 获取当前时间步的输出  \n",
    "  def current_outputs(self):\n",
    "    return torch.cuda.LongTensor(self.next_outputs[-1]).view(-1, 1)\n",
    "  \n",
    "  # 获取当前时间步的前继状态\n",
    "  def previous_outputs(self):\n",
    "    return self.prev_outputs[-1]\n",
    "\n",
    "  # 根据decoder的输出结果，计算得分，选取最高的K个\n",
    "  def beam_search(self, out):\n",
    "    word_num = out.size(1)\n",
    "\n",
    "    # 更新当前的分数\n",
    "    if len(self.prev_outputs) > 0:\n",
    "      new_scores = out + self.scores.unsqueeze(1).expand_as(out)\n",
    "      # 若当前结果是eos，则不应让其继续搜索，故赋予其较低分数\n",
    "      for i in range(self.next_outputs[-1].size(0)):\n",
    "        if self.next_outputs[-1][i] == self.eos:\n",
    "          new_scores[i] = -1e20\n",
    "    else:\n",
    "      new_scores = out[0]\n",
    "    new_scores = new_scores.view(-1)\n",
    "    \n",
    "    # 获取TopK\n",
    "    topK_scores, topK_score_ids = new_scores.topk(self.size, 0, True, True)\n",
    "\n",
    "    self.scores = topK_scores\n",
    "    current_ids = topK_score_ids // word_num\n",
    "    self.prev_outputs.append(current_ids)\n",
    "    self.next_outputs.append((topK_score_ids - current_ids * word_num))\n",
    "\n",
    "    for i in range(self.next_outputs[-1].size(0)):\n",
    "      if self.next_outputs[-1][i] == self.eos:\n",
    "        s = self.scores[i]\n",
    "        self.finished.append((s, len(self.next_outputs) - 1, i))\n",
    "\n",
    "    # 当最高得分已经是eos时，判断可以结束搜索\n",
    "    if self.next_outputs[-1][0] == self.eos:\n",
    "      self.eosTop = True    \n",
    "\n",
    "  # 判断是否结束\n",
    "  def is_finished(self):\n",
    "    return self.eosTop and len(self.finished) >= self.size\n",
    "\n",
    "  # 获取最终的搜索结果\n",
    "  def get_final(self):\n",
    "    if len(self.finished) == 0:\n",
    "      self.finished.append((self.scores[0], len(self.next_outputs) - 1, 0))\n",
    "    self.finished.sort(key=lambda x: -x[0])\n",
    "    if len(self.finished) != self.size:\n",
    "      unfinished = []\n",
    "      for i in range(self.next_outputs[-1].size(0)):\n",
    "        if self.next_outputs[-1][i] != self.eos:\n",
    "          s = self.scores[i]\n",
    "          unfinished.append((s, len(self.next_outputs) - 1, i))\n",
    "      unfinished.sort(key=lambda x: -x[0])\n",
    "      self.finished += unfinished[:self.size - len(self.finished)]\n",
    "    return self.finished[:self.size]\n",
    "\n",
    "  def get_hyp(self, finished):\n",
    "    hyps = []\n",
    "    for _, timestep, k in finished:\n",
    "      hyp = []\n",
    "      for j in range(len(self.prev_outputs[:timestep]) - 1, -1, -1):\n",
    "        hyp.append(self.next_outputs[j + 1][k])\n",
    "        k = self.prev_outputs[j][k]\n",
    "      hyps.append(hyp[::-1])\n",
    "    return hyps\n",
    "\n",
    "  def build_target_tokens(self, preds):\n",
    "    sentence = []\n",
    "    for pred in preds:\n",
    "      tokens = []\n",
    "      for token in pred:\n",
    "        if token == self.eos:\n",
    "          break\n",
    "        tokens.append(token)\n",
    "      sentence.append(tokens)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IKXjLNUX_fl_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RubyCodeBERT(nn.Module):\n",
    "  def __init__(self, encoder, decoder, config, beam_size, cls, sep):\n",
    "    super(RubyCodeBERT, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.config = config\n",
    "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "    self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "    self.softmax = nn.LogSoftmax(dim=-1)\n",
    "    self.register_buffer(\"bias\", torch.tril(torch.ones(2048, 2048)))\n",
    "\n",
    "    self.beam_size = beam_size\n",
    "    self.sos = cls\n",
    "    self.eos = sep\n",
    "    self.max_length = 128\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None, label_mask=None):\n",
    "    # Training\n",
    "    if labels is not None:\n",
    "      outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
    "      encoder_output = outputs[0].permute([1,0,2]).contiguous()\n",
    "      attn_mask = -1e4*(1-self.bias[:labels.shape[1],:labels.shape[1]])\n",
    "      tgt = self.encoder.embeddings(labels).permute([1,0,2]).contiguous()\n",
    "      decoder_output = self.decoder(tgt, encoder_output, tgt_mask=attn_mask, memory_key_padding_mask=(1-attention_mask).bool())\n",
    "      linear_output = self.dense(decoder_output)\n",
    "      hidden_state = torch.tanh(linear_output).permute([1,0,2]).contiguous()\n",
    "      lm_logits = self.lm_head(hidden_state)\n",
    "      # 计算损失函数，排除mask=0的元素的影响\n",
    "      active_loss = label_mask[..., 1:].ne(0).view(-1) == 1\n",
    "      shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "      shift_labels = labels[..., 1:].contiguous()\n",
    "      loss_func = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "      loss = loss_func(shift_logits.view(-1, shift_logits.size(-1))[active_loss], shift_labels.view(-1)[active_loss])\n",
    "\n",
    "      outputs = loss, loss*active_loss.sum(), active_loss.sum()\n",
    "\n",
    "      return outputs\n",
    "    # Prediction\n",
    "    else:\n",
    "\n",
    "      outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
    "      encoder_output = outputs[0].permute([1,0,2]).contiguous()\n",
    "      preds = []\n",
    "      zero = torch.cuda.LongTensor(1).fill_(0)\n",
    "      for i in range(input_ids.shape[0]):\n",
    "        context = encoder_output[:, i:i+1]\n",
    "        context_mask = attention_mask[i:i+1, :]\n",
    "        beam = Beam(self.beam_size, self.sos, self.eos)\n",
    "        inputs = beam.current_outputs()\n",
    "        context = context.repeat(1, self.beam_size, 1)\n",
    "        context_mask = context_mask.repeat(self.beam_size, 1)\n",
    "        for _ in range(self.max_length):\n",
    "          if beam.is_finished():\n",
    "            break\n",
    "          attn_mask = -1e4 * (1-self.bias[:inputs.shape[1],:inputs.shape[1]])\n",
    "          tgt = self.encoder.embeddings(inputs).permute([1,0,2]).contiguous()\n",
    "          out = self.decoder(tgt, context, tgt_mask=attn_mask, memory_key_padding_mask=(1-context_mask).bool())\n",
    "          out = torch.tanh(self.dense(out))\n",
    "          hidden_states = out.permute([1,0,2]).contiguous()[:,-1,:]\n",
    "          out = self.softmax(self.lm_head(hidden_states)).data\n",
    "          beam.beam_search(out)\n",
    "          inputs.data.copy_(inputs.data.index_select(0, beam.previous_outputs()))\n",
    "          inputs = torch.cat((inputs, beam.current_outputs()), -1)\n",
    "        hyp = beam.get_hyp(beam.get_final())\n",
    "        # print(hyp)\n",
    "        pred = beam.build_target_tokens(hyp)[:self.beam_size]\n",
    "        # print(pred)\n",
    "        pred = [torch.cat([x.view(-1) for x in p] + [zero]*(self.max_length-len(p))).view(1, -1) for p in pred]\n",
    "        # print(pred)\n",
    "        preds.append(torch.cat(pred, 0).unsqueeze(0))\n",
    "\n",
    "      preds = torch.cat(preds, 0)\n",
    "      return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmCGSLe60P28",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "传入训练集与验证集，对网络进行微调。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WdyLXaIYKjTP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naojrFjzag-k",
    "outputId": "4f842dab-ee60-4e3c-842c-6dd94823f267",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "\n",
    "net = RubyCodeBERT(model, decoder, config, 3, tokenizer.cls_token_id, tokenizer.sep_token_id)\n",
    "net.to(device)\n",
    "\n",
    "# no_decay = ['bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params':[p for n,p in net.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':0.01},\n",
    "#     {'params':[p for n,p in net.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay':0.0}]\n",
    "\n",
    "epoch_num = 10\n",
    "total_step = epoch_num * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(net.parameters(), lr=5e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_step, num_training_steps=total_step)\n",
    "\n",
    "# save_path = './NL-PL/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGIFwsYdQgbu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNObwBM4An52",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "学习率采用5e-5，epoch设为10，参考自CodeBERT提供的fine-tuning参数建议。\n",
    "\n",
    "受限于colab的GPU使用时长，每个epoch完成训练后保存模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQXMGZ0TL_7X",
    "outputId": "b765832b-efd0-4a15-f4e2-2640e237756c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,   200] loss: 10.288\n",
      "[1,   400] loss: 8.527\n",
      "[1,   600] loss: 6.841\n",
      "[1,   800] loss: 6.149\n",
      "[1,  1000] loss: 5.764\n",
      "[1,  1200] loss: 5.417\n",
      "[1,  1400] loss: 5.249\n",
      "[2,   200] loss: 4.865\n",
      "[2,   400] loss: 4.641\n",
      "[2,   600] loss: 4.583\n",
      "[2,   800] loss: 4.537\n",
      "[2,  1000] loss: 4.456\n",
      "[2,  1200] loss: 4.401\n",
      "[2,  1400] loss: 4.318\n",
      "[3,   200] loss: 4.164\n",
      "[3,   400] loss: 4.148\n",
      "[3,   600] loss: 4.073\n",
      "[3,   800] loss: 4.058\n",
      "[3,  1000] loss: 4.054\n",
      "[3,  1200] loss: 4.015\n",
      "[3,  1400] loss: 4.006\n",
      "[4,   200] loss: 3.874\n",
      "[4,   400] loss: 3.850\n",
      "[4,   600] loss: 3.831\n",
      "[4,   800] loss: 3.838\n",
      "[4,  1000] loss: 3.793\n",
      "[4,  1200] loss: 3.832\n",
      "[4,  1400] loss: 3.796\n",
      "[5,   200] loss: 3.649\n",
      "[5,   400] loss: 3.687\n",
      "[5,   600] loss: 3.642\n",
      "[5,   800] loss: 3.679\n",
      "[5,  1000] loss: 3.689\n",
      "[5,  1200] loss: 3.629\n",
      "[5,  1400] loss: 3.629\n",
      "[6,   200] loss: 3.550\n",
      "[6,   400] loss: 3.516\n",
      "[6,   600] loss: 3.547\n",
      "[6,   800] loss: 3.532\n",
      "[6,  1000] loss: 3.528\n",
      "[6,  1200] loss: 3.481\n",
      "[6,  1400] loss: 3.473\n",
      "[7,   200] loss: 3.443\n",
      "[7,   400] loss: 3.412\n",
      "[7,   600] loss: 3.451\n",
      "[7,   800] loss: 3.399\n",
      "[7,  1000] loss: 3.404\n",
      "[7,  1200] loss: 3.421\n",
      "[7,  1400] loss: 3.390\n",
      "[8,   200] loss: 3.295\n",
      "[8,   400] loss: 3.317\n",
      "[8,   600] loss: 3.348\n",
      "[8,   800] loss: 3.383\n",
      "[8,  1000] loss: 3.366\n",
      "[8,  1200] loss: 3.356\n",
      "[8,  1400] loss: 3.314\n",
      "[9,   200] loss: 3.274\n",
      "[9,   400] loss: 3.270\n",
      "[9,   600] loss: 3.305\n",
      "[9,   800] loss: 3.273\n",
      "[9,  1000] loss: 3.270\n",
      "[9,  1200] loss: 3.302\n",
      "[9,  1400] loss: 3.312\n",
      "[10,   200] loss: 3.193\n",
      "[10,   400] loss: 3.263\n",
      "[10,   600] loss: 3.279\n",
      "[10,   800] loss: 3.253\n",
      "[10,  1000] loss: 3.233\n",
      "[10,  1200] loss: 3.268\n",
      "[10,  1400] loss: 3.299\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "# train_loader = cycle(train_loader)\n",
    "# train_step = 20000\n",
    "\n",
    "# for epoch in range(5):\n",
    "for epoch in range(10):\n",
    "  running_loss = 0\n",
    "  for i, data in enumerate(train_loader):\n",
    "    data = (t[1].to(device) for t in data.items())\n",
    "    input_ids, input_masks, labels, label_masks = data\n",
    "    # print(input_ids.shape)\n",
    "    # print(i)\n",
    "    loss, _, _ = net(input_ids, input_masks, labels, label_masks)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    running_loss += loss.item()\n",
    "    if (i + 1) % 200 == 0:\n",
    "      print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 200))\n",
    "      running_loss = 0\n",
    "  torch.save(net.state_dict(), 'codebert.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyRTbiooQk2R",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test\n",
    "\n",
    "使用测试集进行模型的评估，度量方式采用naive BLEU计算"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "net = RubyCodeBERT(model, decoder, config, 3, tokenizer.cls_token_id, tokenizer.sep_token_id)\n",
    "state_dict = torch.load('codebert.pt')\n",
    "net.load_state_dict(state_dict)\n",
    "net.to(device)"
   ],
   "metadata": {
    "id": "O2fWjHdbjeRA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e72bb36-048e-454b-c7ec-4e3a7e63fbda",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RubyCodeBERT(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (softmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cReNWLiKhzsq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "314afe9c-1246-4029-aea0-06850a8d5c17",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "# eval_loss = 0\n",
    "p = []\n",
    "ground_truth = []\n",
    "for batch in test_loader:\n",
    "  input_ids, input_masks, labels, label_masks = (t[1].to(device) for t in batch.items())\n",
    "  # ground_truth.append(tokenizer.decode(labels))\n",
    "  labels = list(labels)\n",
    "  for label in labels:\n",
    "    label = label.cpu().numpy()\n",
    "    label = list(label)\n",
    "    if 1 in label:\n",
    "      label = label[1:label.index(1)-1]\n",
    "    ground_truth.append(tokenizer.decode(label))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    preds = net(input_ids, input_masks)\n",
    "    for pred in preds:\n",
    "      t = pred[0].cpu().numpy()\n",
    "      t = list(t)\n",
    "      if 0 in t:\n",
    "        t = t[:t.index(0)]\n",
    "      text = tokenizer.decode(t, clean_up_tokenization_sapces=False)\n",
    "      p.append(text)\n",
    "\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0ALpVK-tPX-r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(predictions, ground_truth):\n",
    "  length = len(predictions)\n",
    "  # print(length)\n",
    "  bleu_sum = 0\n",
    "  for i in range(length):\n",
    "    pred = predictions[i].split(' ')\n",
    "    truth = ground_truth[i].split(' ')\n",
    "    count = 0\n",
    "    for word in pred:\n",
    "      if word in truth:\n",
    "        count += 1\n",
    "    bleu_sum += count / len(pred)\n",
    "  final_score = bleu_sum / length\n",
    "  return final_score"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(calculate_bleu(p, ground_truth))"
   ],
   "metadata": {
    "id": "6Cti_7fXmpjy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "44b83c4a-4d4a-4ddc-9bc1-7d3ec87b1e27",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13240009654173585\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "gn7OYA1tp8MY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BjnOZpx8J8y6"
   ],
   "name": "CodeBERT.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "cb1f6ebaf6294b58b23f03bc9c350538": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be45805e1a88493fb9851f9b445a1d5e",
       "IPY_MODEL_cc5d381b633445c79860e9ae46afb321",
       "IPY_MODEL_e3369bc9434f4dae98e7d3b23b8a4882"
      ],
      "layout": "IPY_MODEL_c65f49431b524501a2e066d4bab2ea40"
     }
    },
    "be45805e1a88493fb9851f9b445a1d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_627bad0892b74ffba74aee2d31d15d63",
      "placeholder": "​",
      "style": "IPY_MODEL_bd463ee0978e4fb09627d8471617c151",
      "value": "100%"
     }
    },
    "cc5d381b633445c79860e9ae46afb321": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa387c004dba4d06bef496f5c5bc52e8",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf28f5c15da54fd2887942a1b78fafd6",
      "value": 3
     }
    },
    "e3369bc9434f4dae98e7d3b23b8a4882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c3b502231b64cce9ecb61b3be78be75",
      "placeholder": "​",
      "style": "IPY_MODEL_78e7d88ecabb4b97b5e7c4465b909462",
      "value": " 3/3 [00:00&lt;00:00, 67.74it/s]"
     }
    },
    "c65f49431b524501a2e066d4bab2ea40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "627bad0892b74ffba74aee2d31d15d63": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd463ee0978e4fb09627d8471617c151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa387c004dba4d06bef496f5c5bc52e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf28f5c15da54fd2887942a1b78fafd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c3b502231b64cce9ecb61b3be78be75": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78e7d88ecabb4b97b5e7c4465b909462": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0443e01cb173464aa098ae1a66c76697": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7e5c6955eba40178e47d5d2a46d208b",
       "IPY_MODEL_c4085357152e4360a10106286f011912",
       "IPY_MODEL_60fbd31e9c374f738e2ac3fc136b9c2b"
      ],
      "layout": "IPY_MODEL_5d351f33afe943bd8c56ed7083b4b256"
     }
    },
    "f7e5c6955eba40178e47d5d2a46d208b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc2e1192a5c34f40b299a964a32a684b",
      "placeholder": "​",
      "style": "IPY_MODEL_b5bcaec573844a7198688521f493e561",
      "value": "100%"
     }
    },
    "c4085357152e4360a10106286f011912": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_975f9de21d5a4c04b088d2988bf9ab1d",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d07085ec7e3488091d890f0dbb12c5b",
      "value": 25
     }
    },
    "60fbd31e9c374f738e2ac3fc136b9c2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e9ccb8d25ee497287bc316936e90650",
      "placeholder": "​",
      "style": "IPY_MODEL_49ac377fcf5a492c8dcd8d1fa994376e",
      "value": " 25/25 [00:35&lt;00:00,  1.32s/ba]"
     }
    },
    "5d351f33afe943bd8c56ed7083b4b256": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc2e1192a5c34f40b299a964a32a684b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5bcaec573844a7198688521f493e561": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "975f9de21d5a4c04b088d2988bf9ab1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d07085ec7e3488091d890f0dbb12c5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e9ccb8d25ee497287bc316936e90650": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49ac377fcf5a492c8dcd8d1fa994376e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8530610645147808dbb6e012263e262": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c807713abaf4d8fb2942e83d9a7ec9f",
       "IPY_MODEL_ebecfc1a99d84518b93f1504a7bfd60f",
       "IPY_MODEL_de1e86f106b24098aa6c1fbb637bda71"
      ],
      "layout": "IPY_MODEL_7c4f309990594b35806d0cab9f69e7fe"
     }
    },
    "5c807713abaf4d8fb2942e83d9a7ec9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c1bbc07981243618741cdbc54cbebf2",
      "placeholder": "​",
      "style": "IPY_MODEL_fcf10595b6554b199e2be35e7a443a03",
      "value": "100%"
     }
    },
    "ebecfc1a99d84518b93f1504a7bfd60f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26c93c2044ea46ae8a706fff0c8c5b8e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b22eb842398447684ef1ec4e7a36561",
      "value": 2
     }
    },
    "de1e86f106b24098aa6c1fbb637bda71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d2a8d82b6924ac69ccb813ba489756d",
      "placeholder": "​",
      "style": "IPY_MODEL_7e93b19d2c7a45a7ab6371b182eea239",
      "value": " 2/2 [00:01&lt;00:00,  1.17ba/s]"
     }
    },
    "7c4f309990594b35806d0cab9f69e7fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c1bbc07981243618741cdbc54cbebf2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf10595b6554b199e2be35e7a443a03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26c93c2044ea46ae8a706fff0c8c5b8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b22eb842398447684ef1ec4e7a36561": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d2a8d82b6924ac69ccb813ba489756d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e93b19d2c7a45a7ab6371b182eea239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74a74652621e4f15b6f5adfd3ca03165": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7207703e15ab4e9883f16911a4050e01",
       "IPY_MODEL_a5af7fba5ee4404ebb2d894de6255535",
       "IPY_MODEL_ea5735e45e28417298b24c0f08b4b58b"
      ],
      "layout": "IPY_MODEL_e0e47e7ac29f4f9586987a37b8c5a3da"
     }
    },
    "7207703e15ab4e9883f16911a4050e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ac2ef93aaea4b39bd0896325048872c",
      "placeholder": "​",
      "style": "IPY_MODEL_b83e5cb2950f4371870d651814b8d2e5",
      "value": "100%"
     }
    },
    "a5af7fba5ee4404ebb2d894de6255535": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b789a5ac7fd4390b7096c3970d61344",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14d8aed42b334b899abae5e549742911",
      "value": 2
     }
    },
    "ea5735e45e28417298b24c0f08b4b58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1f6a8ae102a4a3db3291bfc0cb0ce3a",
      "placeholder": "​",
      "style": "IPY_MODEL_4e6800e6061f4ac18c38d9a6f2c6d45a",
      "value": " 2/2 [00:01&lt;00:00,  1.33ba/s]"
     }
    },
    "e0e47e7ac29f4f9586987a37b8c5a3da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ac2ef93aaea4b39bd0896325048872c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b83e5cb2950f4371870d651814b8d2e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b789a5ac7fd4390b7096c3970d61344": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d8aed42b334b899abae5e549742911": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1f6a8ae102a4a3db3291bfc0cb0ce3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e6800e6061f4ac18c38d9a6f2c6d45a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}